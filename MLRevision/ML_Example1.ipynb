{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Example1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezbyA2gdOluG"
      },
      "source": [
        "For this project the SL defined by DS is 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hBika8kH6JQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_x-JkIaNB32"
      },
      "source": [
        "data = pd.read_csv('iris.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3xahtAdNEng",
        "outputId": "95e51c4a-9f06-4612-e45d-816779529098"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   species       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "G5SmyLvMNFEI",
        "outputId": "1fb88f66-7f9e-46dc-bd4e-5eb936235abe"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5mRmHZCNFk-"
      },
      "source": [
        "# We assume data preprocessing is done\n",
        "# Seperate your data as features and label\n",
        "\n",
        "features = data.iloc[:,:-1].values\n",
        "label = data.iloc[:,4].values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Tab7itNU1v"
      },
      "source": [
        "# Split the data as Training set and Testing Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(features,\n",
        "                                                 label,\n",
        "                                                 test_size=0.2,\n",
        "                                                 random_state=10)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mTB-Hh8Np_t",
        "outputId": "46332f46-3c64-4966-cfd5-b1c37d74e02f"
      },
      "source": [
        "#Training Process Starts\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqmHw3SSN6DF",
        "outputId": "42fb01d2-b04c-4177-a311-800cfee664a0"
      },
      "source": [
        "#Quality Check\n",
        "# 1. Ensure your model is a generalized model\n",
        "\n",
        "# To ensure the model is generalized following two conditions must be met\n",
        "# 1. TestingScore must be greater than TrainingScore\n",
        "# 2. TestingScore must be greater than or equal to CL ie. 0.9\n",
        "\n",
        "print(\"Training Score is: \",model.score(X_train,y_train))\n",
        "print(\"Testing Score is: \",model.score(X_test,y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Score is:  0.975\n",
            "Testing Score is:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFwwi3hJSbW7",
        "outputId": "e4c7ec54-272e-4934-88aa-e71acac9d76c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(label,model.predict(features))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[50,  0,  0],\n",
              "       [ 0, 47,  3],\n",
              "       [ 0,  0, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnJ6NjRhVeTY",
        "outputId": "0ce18297-cfd3-4ff7-f2bb-c66107395aad"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(label,model.predict(features)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        50\n",
            "  versicolor       1.00      0.94      0.97        50\n",
            "   virginica       0.94      1.00      0.97        50\n",
            "\n",
            "    accuracy                           0.98       150\n",
            "   macro avg       0.98      0.98      0.98       150\n",
            "weighted avg       0.98      0.98      0.98       150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNKzj6kRONFg"
      },
      "source": [
        "# 2. Since the dataset is balanced, we will choose accuracy as a decision\n",
        "# metric for quality\n",
        "# if acc(test) > CL --- YES"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCU5TXJoTkTQ"
      },
      "source": [
        "# Therefore the model is approved for deployment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmhTFPApXMLe",
        "outputId": "be88974c-35c4-4b56-f932-63249a8b0aee"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MH2YtN2XP54",
        "outputId": "2719b0c2-b9f5-4692-935c-a67c4963e2e3"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnIaqJ6VXSA9",
        "outputId": "efb46dc2-33d9-4ac4-b61b-a28ffaf90f19"
      },
      "source": [
        "X_train.ndim"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkpd42vJW3Sg",
        "outputId": "e7ef3696-ebc6-4dc1-d0b6-98145f0119c8"
      },
      "source": [
        "# Deployment Test \n",
        "\n",
        "sepal_length = float(input(\"Enter Sepal Length: \")\t)\n",
        "sepal_width\t= float(input(\"Enter Sepal Width: \")\t)\n",
        "petal_length\t= float(input(\"Enter Petal Length: \")\t)\n",
        "petal_width= float(input(\"Enter Petal Width: \")\t)\n",
        "\n",
        "featureSet = np.array([[sepal_length,sepal_width,petal_length,petal_width]])\n",
        "\n",
        "print(\"Predicted Flower is \",model.predict(featureSet)[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Sepal Length: 3.5\n",
            "Enter Sepal Width: 1.5\n",
            "Enter Petal Length: 1.4\n",
            "Enter Petal Width: 0.3\n",
            "Predicted Flower is  setosa\n"
          ]
        }
      ]
    }
  ]
}